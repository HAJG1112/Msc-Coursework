{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_logistic(df_train, df_test):\n",
    "\n",
    "    dtypes_cat = {\n",
    "     'target': 'int8',\n",
    "     'a01': \"category\",\n",
    "     'a02': \"category\",\n",
    "     'a03': \"category\",\n",
    "     'a10': \"category\",\n",
    "     'a11': \"int8\",\n",
    "     'a12': \"category\",\n",
    "     'a13': \"category\",\n",
    "     'a16': \"category\",\n",
    "     'a17': \"category\",\n",
    "     'a18': \"category\",\n",
    "     'a19': \"category\",\n",
    "     'a20': \"category\",\n",
    "     'b02': \"category\",\n",
    "     'b03': \"category\",\n",
    "     'b04': \"category\",\n",
    "     'b07': \"category\",\n",
    "     'c02': \"category\",\n",
    "     'c04': \"category\",\n",
    "     'c05': \"category\",\n",
    "     'c06': \"category\",\n",
    "     'c07': \"category\",\n",
    "     'c08': \"category\",\n",
    "     'c09': \"category\",\n",
    "     'e01': \"category\",\n",
    "     'e03': \"category\",\n",
    "     'e11': \"category\",\n",
    "     'e13': \"category\",\n",
    "     'e14': \"category\",\n",
    "     'e21': \"category\",\n",
    "     'e22': \"category\",\n",
    "     'e24': \"category\",\n",
    "     'e25': \"category\",\n",
    "     'e17': \"category\",\n",
    "     'e18': \"category\",\n",
    "     'e19': \"category\",\n",
    "     'e20': \"category\",\n",
    "     'f03': \"category\",\n",
    "     'f04': \"category\",\n",
    "     'f05': \"category\",\n",
    "     'f07': \"category\",\n",
    "     'f09': \"category\",\n",
    "     'f27': \"category\",\n",
    "     'f29': \"category\",\n",
    "     'f30': \"category\",\n",
    "     'f33': \"category\",\n",
    "     'f34': \"category\",\n",
    "     'f10': \"category\",\n",
    "     'a04': 'int16',\n",
    "     'a05': 'int8',\n",
    "     'a06': 'int8',\n",
    "     'a07': 'int8',\n",
    "     'a08': 'int8',\n",
    "     'a09': 'int8',\n",
    "     'a14': 'int8',\n",
    "     'a15': 'int8',\n",
    "     'b01': 'int8',\n",
    "     'b05': 'int8',\n",
    "     'b06': 'int8',\n",
    "     'c01': 'int8',\n",
    "     'c03': 'int8',\n",
    "     'd01': 'int8',\n",
    "     'd02': 'int8',\n",
    "     'd03': 'int8',\n",
    "     'e02': 'int8',\n",
    "     'e04': 'int8',\n",
    "     'e05': 'int8',\n",
    "     'e06': 'int8',\n",
    "     'e07': 'int8',\n",
    "     'e08': 'int8',\n",
    "     'e09': 'int8',\n",
    "     'e12': 'int8',\n",
    "     'e15': 'int8',\n",
    "     'e16': 'int8',\n",
    "     'e23': 'int8',\n",
    "     'f01': 'int8',\n",
    "     'f02': 'int8',\n",
    "     'f06': 'int8',\n",
    "     'f08': 'int8',\n",
    "     'f11': 'int8',\n",
    "     'f13': 'int8',\n",
    "     'f15': 'int8',\n",
    "     'f16': 'int8',\n",
    "     'f17': 'int8',\n",
    "     'f18': 'int8',\n",
    "     'f19': 'int8',\n",
    "     'f20': 'int8',\n",
    "     'f21': 'int8',\n",
    "     'f22': 'int8',\n",
    "     'f23': 'int8',\n",
    "     'f24': 'int8',\n",
    "     'f25': 'int8',\n",
    "     'f26': 'int8',\n",
    "     'f28': 'int8',\n",
    "     'f31': 'int8',\n",
    "     'f32': 'int8',\n",
    "     'unique_id': 'int64'}\n",
    "\n",
    "\n",
    "    dtypes_object = {\n",
    "     'a01': \"O\",\n",
    "     'a02': \"O\",\n",
    "     'a03': \"O\",\n",
    "     'a10': \"O\",\n",
    "     'a11': \"int8\",\n",
    "     'a12': \"O\",\n",
    "     'a13': \"O\",\n",
    "     'a16': \"O\",\n",
    "     'a17': \"O\",\n",
    "     'a18': \"O\",\n",
    "     'a19': \"O\",\n",
    "     'a20': \"O\",\n",
    "     'b02': \"O\",\n",
    "     'b03': \"O\",\n",
    "     'b04': \"O\",\n",
    "     'b07': \"O\",\n",
    "     'c02': \"O\",\n",
    "     'c04': \"O\",\n",
    "     'c05': \"O\",\n",
    "     'c06': \"O\",\n",
    "     'c07': \"O\",\n",
    "     'c08': \"O\",\n",
    "     'c09': \"O\",\n",
    "     'e01': \"O\",\n",
    "     'e03': \"O\",\n",
    "     'e11': \"O\",\n",
    "     'e13': \"O\",\n",
    "     'e14': \"O\",\n",
    "     'e21': \"O\",\n",
    "     'e22': \"O\",\n",
    "     'e24': \"O\",\n",
    "     'e25': \"O\",\n",
    "     'e17': \"O\",\n",
    "     'e18': \"O\",\n",
    "     'e19': \"O\",\n",
    "     'e20': \"O\",\n",
    "     'f03': \"O\",\n",
    "     'f04': \"O\",\n",
    "     'f05': \"O\",\n",
    "     'f07': \"O\",\n",
    "     'f09': \"O\",\n",
    "     'f27': \"O\",\n",
    "     'f29': \"O\",\n",
    "     'f30': \"O\",\n",
    "     'f33': \"O\",\n",
    "     'f34': \"O\",\n",
    "     'f10': \"O\",\n",
    "     'a04': 'int16',\n",
    "     'a05': 'int8',\n",
    "     'a06': 'int8',\n",
    "     'a07': 'int8',\n",
    "     'a08': 'int8',\n",
    "     'a09': 'int8',\n",
    "     'a14': 'int8',\n",
    "     'a15': 'int8',\n",
    "     'b01': 'int8',\n",
    "     'b05': 'int8',\n",
    "     'b06': 'int8',\n",
    "     'c01': 'int8',\n",
    "     'c03': 'int8',\n",
    "     'd01': 'int8',\n",
    "     'd02': 'int8',\n",
    "     'd03': 'int8',\n",
    "     'e02': 'int8',\n",
    "     'e04': 'int8',\n",
    "     'e05': 'int8',\n",
    "     'e06': 'int8',\n",
    "     'e07': 'int8',\n",
    "     'e08': 'int8',\n",
    "     'e09': 'int8',\n",
    "     'e12': 'int8',\n",
    "     'e15': 'int8',\n",
    "     'e16': 'int8',\n",
    "     'e23': 'int8',\n",
    "     'f01': 'int8',\n",
    "     'f02': 'int8',\n",
    "     'f06': 'int8',\n",
    "     'f08': 'int8',\n",
    "     'f11': 'int8',\n",
    "     'f13': 'int8',\n",
    "     'f15': 'int8',\n",
    "     'f16': 'int8',\n",
    "     'f17': 'int8',\n",
    "     'f18': 'int8',\n",
    "     'f19': 'int8',\n",
    "     'f20': 'int8',\n",
    "     'f21': 'int8',\n",
    "     'f22': 'int8',\n",
    "     'f23': 'int8',\n",
    "     'f24': 'int8',\n",
    "     'f25': 'int8',\n",
    "     'f26': 'int8',\n",
    "     'f28': 'int8',\n",
    "     'f31': 'int8',\n",
    "     'f32': 'int8',\n",
    "     'unique_id': 'int64'}\n",
    "    \n",
    "    '''\n",
    "    Importing of modules for the function and setting of dtypes and variables\n",
    "    '''\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    import h2o \n",
    "    from h2o.estimators.glm import H2OGeneralizedLinearEstimator   #allows elastic net\n",
    "    from h2o.grid.grid_search import H2OGridSearch    #hyper parameter optimization\n",
    "    from sklearn import preprocessing\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    %matplotlib inline\n",
    "    #from sklearn.metrics import roc_auc_score\n",
    "    #from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    vars_all = df_train.columns.values\n",
    "    vars_ind_hccv = ['e17', 'e18', 'e19', 'f10']\n",
    "    vars_ind_categorical = list(df_train.columns[df_train.dtypes == 'category'])\n",
    "    \n",
    "    #replace in df_test, the relevant categorical variables\n",
    "    for var in vars_ind_categorical:\n",
    "        var_levels = df_train[var].cat.categories.values\n",
    "        df_test[var] = pd.Categorical(df_test[var], categories=var_levels, ordered=False)\n",
    "        \n",
    "    var_dep = ['target']\n",
    "    vars_notToUse = ['unique_id'] \n",
    "    vars_ind = [var for var in vars_all if var not in (vars_notToUse + var_dep)]\n",
    "    vars_ind_numeric = [var for var in vars_ind if var not in vars_ind_categorical]\n",
    "    \n",
    "\n",
    "   # data preprocessing section\n",
    "    \n",
    "    '''\n",
    "   # Related functions for processing here\n",
    "    '''\n",
    "    def replace_missing(df, numeric_type_var):\n",
    "        import numpy as np\n",
    "        df = df.replace({-99:np.nan})   #replace missing with nan\n",
    "        df[vars_ind_numeric] = df[vars_ind_numeric].apply(lambda x: x.fillna(x.mean()), axis = 0) #lambda to fill with mean\n",
    "        df['numeric'] = df['f10']/df['e19']  #add numeric column based on past testing\n",
    "        return df\n",
    "\n",
    "    def fn_tosplines(x):\n",
    "        x = x.values\n",
    "        # hack: remove zeros to avoid issues where lots of values are zero\n",
    "        x_nonzero = x[x != 0]\n",
    "        ptiles = np.percentile(x, [5, 10, 20, 40, 60, 80, 90, 95])\n",
    "        ptiles = np.unique(ptiles)\n",
    "        df_ptiles = pd.DataFrame({var: x})\n",
    "        for idx, ptile in enumerate(ptiles):\n",
    "            df_ptiles[var + '_' + str(idx)] = np.maximum(0, x - ptiles[idx])\n",
    "        return(df_ptiles)\n",
    "\n",
    "    #import and apply the category encoder on high caridnality and larger std dev on low cardinality.\n",
    "    #due to the high cardinality of alot of variables within the categorical,\n",
    "    # i have chosent o convert all categorical types to numerical as linear regressions demand \n",
    "    # a numeric type object to be parsed into it.\n",
    "    \n",
    "    from category_encoders import CatBoostEncoder\n",
    "    vars_cat_nothccv = list(set(vars_ind_categorical) - set(vars_ind_hccv))\n",
    "    enc = CatBoostEncoder(cols = vars_ind_hccv, sigma = 0.1) #encode high cardinality\n",
    "    enc1 = CatBoostEncoder(cols = vars_cat_nothccv, sigma = 0.25)\n",
    "    enc.fit(df_train, df_train['target'])\n",
    "    enc1.fit(df_train, df_train['target'])\n",
    "    df_train = enc.transform(df_train)\n",
    "    df_train = enc1.transform(df_train)\n",
    "    df_test['target'] = np.nan\n",
    "    df_test = enc.transform(df_test)\n",
    "    df_test = enc1.transform(df_test)\n",
    "    df_test.drop(['target'], axis = 1)\n",
    "\n",
    "    ## replace missing values for numerics before splines to prevent nan continuance\n",
    "    df_train = replace_missing(df_train, vars_ind_numeric)  \n",
    "    df_test = replace_missing(df_test, vars_ind_numeric)\n",
    "    vars_ind_numeric+=['numeric']\n",
    "\n",
    "    #splines\n",
    "    num = 8\n",
    "    vars_ind_tospline1 = df_train[vars_ind_numeric].columns[(df_train[vars_ind_numeric].nunique() > num)].tolist()\n",
    "    vars_ind_tospline2 = df_test[vars_ind_numeric].columns[(df_test[vars_ind_numeric].nunique() > num)].tolist()\n",
    "\n",
    "    for var in vars_ind_tospline1:\n",
    "        df_ptiles = fn_tosplines(df_train[var])\n",
    "        df_train.drop(columns=[var], inplace=True)\n",
    "        vars_ind_numeric.remove(var)\n",
    "        df_train = pd.concat([df_train, df_ptiles], axis=1, sort=False)\n",
    "        vars_ind_numeric.extend(df_ptiles.columns.tolist())\n",
    "\n",
    "    for var in vars_ind_tospline2:\n",
    "        df_ptiles_test = fn_tosplines(df_train[var])\n",
    "        df_test.drop(columns=[var], inplace = True)\n",
    "        df_test = pd.concat([df_test, df_ptiles_test], axis=1, sort=False)\n",
    "    \n",
    "    #train and validation splitting in the testing and connecting to h2o\n",
    "    df_design = df_train\n",
    "    del df_train\n",
    "    \n",
    "    df_train, df_val = train_test_split(df_design, test_size = 75000) #30% split train, test\n",
    "    \n",
    "    h2o.connect()\n",
    "    \n",
    "    h2o_df_train = h2o.H2OFrame(df_train[vars_ind_numeric + vars_ind_categorical + var_dep],\n",
    "                               destination_frame='df_train')\n",
    "\n",
    "    h2o_df_val = h2o.H2OFrame(df_val[vars_ind_numeric + vars_ind_categorical + var_dep],\n",
    "                               destination_frame='df_val')\n",
    "\n",
    "    h2o_df_design = h2o.H2OFrame(df_design[vars_ind_numeric + vars_ind_categorical + var_dep],\n",
    "                               destination_frame='df_design')\n",
    "    \n",
    "    features = vars_ind_numeric+vars_ind_categorical\n",
    "\n",
    "    model = H2OGeneralizedLinearEstimator(alpha = 0.7,   #high alpha to penalise\n",
    "                                        family=\"Binomial\",\n",
    "                                        lambda_ = 2.661E-8,\n",
    "                                        nfolds=15,\n",
    "                                        early_stopping=False,\n",
    "                                        standardize = False,\n",
    "                                        #missing_values_handling = \"mean_imputation\",  #mean impute instead of skip\n",
    "                                        interactions = ['e20','e14' ],   #these two variables had high positive coefficients,\n",
    "                                                                             #interacting them improved the MAE and MSE\n",
    "                                        seed = 2020)\n",
    "\n",
    "\n",
    "    model.train(y = \"target\",\n",
    "               x = features, \n",
    "               training_frame = h2o_df_design)  #was done using the train first, then val, but changed it back\n",
    "                            \n",
    "    df_test = df_test[vars_ind_numeric + vars_ind_categorical]\n",
    "    \n",
    "        '''\n",
    "        How I conducted my testing of variables before using the grid search to arrive at my final model\n",
    "\n",
    "        # score is the validation accuracy score for the roc_auc\n",
    "        #hccv = 0.25, replace_missing, stand(numeric), alpha = 0.75, score= 0.73445 \n",
    "        #hccv = 0.25 on hccv, replace_missing, alpha =0.75 score = 0.812457706953913  \n",
    "        #hccv = 0.25 on all categorical, replace_missing, alpha =0.75 score = 0.8072412286152757  #struggles with categorical\n",
    "        #hccv = 0.25 on all categorical, replace_missing, splines(8), alpha =0.75 score = 0.8098616750219919  #struggles with categorical\n",
    "        #hccv = 0.25 on hccv, replace_missing, splines(8), alpha =0.75 score = 0.8192177001040986   \n",
    "        #hccv = 0.25 on hccv, replace_missing, splines(8), alpha =0.75, stand, score = 0.8191806750957351 \n",
    "        #hccv = 0.5 on hccv, replace_missing, splines(8), alpha =0.75, score = 0.7826790072994181 \n",
    "        #hccv = 0.2 on hccv, replace_missing, splines(8), alpha =0.75, score = 0.8250429051246577\n",
    "        #hccv = 0.1 on hccv, replace_missing, splines(8), alpha =0.75, score = 0.8401192507365349 \n",
    "        #hccv = 0.1 on hccv, replace_missing, splines(8), alpha =0.5, score = 0.8391110396025838\n",
    "        #hccv = 0.1 on hccv, replace_missing, splines(8), alpha =0.99, score = 0.8423509117511592\n",
    "        #hccv = 0.1 on hccv, replace_missing, splines(8), alpha =0.99, interactions = ['f13_0', 'f02_2'] chosen due to neg coefs score = 0.8416125625765634\n",
    "        #hccv = 0.1 on hccv, replace_missing, splines(8), alpha =0.99, interactions = ['f13_0', 'e14'] chosen due to neg coefs score = 0.8418030047209545\n",
    "        #hccv = 0.1 on hccv, replace_missing, splines(8), alpha =0.99, interactions = ['e20', 'e14'] chosen due to neg coefs score = 0.851440205269665\n",
    "\n",
    "    #call predictions for checking of results\n",
    "        preds_train = model.predict(h2o_df_train).as_data_frame()\n",
    "        preds_val = model.predict(h2o_df_val).as_data_frame()\n",
    "        preds_des = model.predict(h2o_df_design).as_data_frame()\n",
    "\n",
    "        #val_score = (roc_auc_score(h2o_df_val[var_dep], preds_val['p1'].values))\n",
    "        #test_score = (roc_auc_score(df_test[var_dep], preds_train['p1'].values))\n",
    "        #print('test score:{}'.format(test_score))\n",
    "        #print('test score: {}'.format(test_score))\n",
    "        #print('validation score:{}'.format(val_score))\n",
    "\n",
    "    #quick binary method  to check the accuracy of my predictions to check i was on the right path\n",
    "    #this was because the GLMtend to overfit AUC on the validation set\n",
    "\n",
    "        def binary_accuracy(prediction, y_value):\n",
    "        a = sum(prediction==y_value)\n",
    "        b = len(prediction)\n",
    "        accuracy = a/b\n",
    "        return accuracy\n",
    "\n",
    "        df = h2o_df_design[var_dep].as_data_frame().values\n",
    "        df.reshape(1,-1)\n",
    "\n",
    "\n",
    "        #test_acc = (binary_accuracy(preds_train['predict'].values, df_train['target'].values))\n",
    "        val_acc = (binary_accuracy(preds_val['predict'].values, df_val['target'].values))\n",
    "        design_acc = (binary_accuracy(preds_des['predict'].values, df_design['target'].values))\n",
    "\n",
    "        #print('test_acc: {} '.format(test_acc))\n",
    "        print('val_acc: {} '.format(val_acc))\n",
    "        print('design_acc: {}'.format(design_acc))\n",
    "\n",
    "    #checking the roc on the valuation\n",
    "    roc_score_val = (roc_auc_score(df_val[var_dep], preds_val['p1'].values))\n",
    "    print( roc_score_val)\n",
    "\n",
    "    # observing the coefficients, our interactions as well as 'numeric' variable are highly significant!\n",
    "    model.std_coef_plot(30)\n",
    "\n",
    "\n",
    "    from h2o.grid.grid_search import H2OGridSearch\n",
    "    criteria = {# The default strategy, \"Cartesian\", covers the entire space of h-p combinations. \n",
    "                \"strategy\": \"RandomDiscrete\", \n",
    "                \"max_runtime_secs\": 10000,   'lots of time as local run model'\n",
    "                \"max_models\": 30,\n",
    "                \"stopping_metric\": \"AUTO\",\n",
    "                \"seed\": 2020}\n",
    "\n",
    "    alpha_opts = np.arange(0, 1, 0.1).tolist()\n",
    "    alpha_opts = alpha_opts + [0.99]\n",
    "    hyper_parameters = {\"alpha\":alpha_opts}\n",
    "\n",
    "    # How i optimized my search parameters using gridsearch\n",
    "    grid = H2OGridSearch(H2OGeneralizedLinearEstimator(  \n",
    "                                            family=\"Binomial\",\n",
    "                                            lambda_search=True,\n",
    "                                            lambda_min_ratio=1e-8,\n",
    "                                            nlambdas=100,\n",
    "                                            nfolds=15,\n",
    "                                            early_stopping=False,\n",
    "                                            standardize = False,\n",
    "                                            interactions = ['e20','e14' ],   \n",
    "                                            seed = 2020),\n",
    "\n",
    "                         hyper_params=hyper_parameters,  \n",
    "                         grid_id='g1',\n",
    "                         search_criteria=criteria)  #search criteria is passed a dictionary\n",
    "\n",
    "    grid.train(y = \"target\",\n",
    "               x = features, \n",
    "               training_frame = h2o_df_train\n",
    "               )\n",
    "\n",
    "    '''\n",
    "    \n",
    "    return(model, df_test, 0.82910)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justi\\Dropbox\\AML\\Projects\\Main_assignment\\Pcode\n",
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>3 hours 25 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/London</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 14 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Haisun_6o497e</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>11.67 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         3 hours 25 mins\n",
       "H2O_cluster_timezone:       Europe/London\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.4\n",
       "H2O_cluster_version_age:    1 month and 14 days\n",
       "H2O_cluster_name:           H2O_from_python_Haisun_6o497e\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    11.67 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.4 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the data\n",
    "import os\n",
    "import pickle\n",
    "import h2o\n",
    "print(os.getcwd())\n",
    "dirRawData = \"../input/\"\n",
    "dirPData =   \"../PData/\"\n",
    "f_name = dirPData + '01_df_250k.pickle'\n",
    "\n",
    "with (open(f_name, \"rb\")) as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "df_train = dict_['df_train']\n",
    "df_test = dict_['df_test']\n",
    "\n",
    "del f_name, dict_\n",
    "\n",
    "h2o.init(port=54321,\n",
    "        min_mem_size = \"10g\",\n",
    "        max_mem_size = \"12g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://localhost:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>3 hours 25 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/London</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 14 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Haisun_6o497e</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>11.67 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         3 hours 25 mins\n",
       "H2O_cluster_timezone:       Europe/London\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.4\n",
       "H2O_cluster_version_age:    1 month and 14 days\n",
       "H2O_cluster_name:           H2O_from_python_Haisun_6o497e\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    11.67 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.4 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_, test, score = fn_logistic(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "h2o_df_test = h2o.H2OFrame(test,\n",
    "                               destination_frame='df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_test= model_.predict(h2o_df_test).as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.992541</td>\n",
       "      <td>0.007459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.089321</td>\n",
       "      <td>0.910679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.933557</td>\n",
       "      <td>0.066443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.789213</td>\n",
       "      <td>0.210787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.978461</td>\n",
       "      <td>0.021539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296685</th>\n",
       "      <td>1</td>\n",
       "      <td>0.040053</td>\n",
       "      <td>0.959947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296686</th>\n",
       "      <td>0</td>\n",
       "      <td>0.975798</td>\n",
       "      <td>0.024202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296687</th>\n",
       "      <td>1</td>\n",
       "      <td>0.263259</td>\n",
       "      <td>0.736741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296688</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.099184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296689</th>\n",
       "      <td>0</td>\n",
       "      <td>0.880019</td>\n",
       "      <td>0.119981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296690 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        predict        p0        p1\n",
       "0             0  0.992541  0.007459\n",
       "1             1  0.089321  0.910679\n",
       "2             0  0.933557  0.066443\n",
       "3             0  0.789213  0.210787\n",
       "4             0  0.978461  0.021539\n",
       "...         ...       ...       ...\n",
       "296685        1  0.040053  0.959947\n",
       "296686        0  0.975798  0.024202\n",
       "296687        1  0.263259  0.736741\n",
       "296688        0  0.900816  0.099184\n",
       "296689        0  0.880019  0.119981\n",
       "\n",
       "[296690 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
